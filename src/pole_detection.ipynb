{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road-Pole/Stick Detection on Edge Devices\n",
    "\n",
    "a research paper by Sindre L. Øyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 Introduction\n",
    "In this paper, I will investigate the feasibility of using edge devices for pole detection, applying modern solutions for Visual Intelligence (VI). First, the data preparation phase will be explained, where the data set is visualized and discussed. Second, the model selection phase will be documented, discussing available options weighing them against one another based on performance and accuracy. Third, a model will be trained on the dataset and monitored based on performance metrics. Hence, three final sections will document (1) the testing and evaluation phase based on relevant metrics, (2) the deployment feasibility of the model on e.g., an edge device, and (3) the sustainability of the training and inference of the developed model will be discussed with examples and comparisons of energy consumption.\n",
    "\n",
    "Road poles, commonly referred to as \"brøytestikker\" in Norwegian, are central in navigation guidance during the winter - especially for giving guidance to plowers as to where the road edge is positioned on overly snowy roads. Recently, in the realm of Cooperative, Connected and Automated Mobility (CCAM) (i.e., self-driving vehicles) research, studies investigate the feasibility of using VI technology to detect road poles and more efficiently navigate Norwegian roads under diverse conditions. Thus, road poles may have an ever-growing importance in the Norwegian infrastructure and the dataset collection which on the larger scale is the motivation of this research paper.\n",
    "\n",
    "The end goal is to produce an accurate model that has the potential to be ran with real-time inference on a hardware-restricted edge-device, such as a smartphone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 NAPLab LiDAR Image Dataset\n",
    "\n",
    "NAPLab has collected and annotated a dataset of LiDAR images of poles which has been made available for this project. As mentioned in the repository README, this dataset is unavailable for redistribution. However, with access to the NTNU Idun cluster the dataset is made found under `/cluster/projects/vc/data/ad/open/Poles`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Discussion of the NAPLab Dataset\n",
    "\n",
    "The dataset contains annotated data with one class as the basis for detection, namely `pole`, which refers to a road pole. While writing this paper, the dataset comprises a total of 2 259 images, divided into a train and a validation split of 1 809 and 450 images, respectively. In the figure below, an example image from the dataset is linked. The dataset has a total of 4 230 annotations, with an average of 1.9 annotations per image; indicating the expected result that road poles come in pairs, with some exceptions. The images are of median image ratio `1024 x 128` and are thus of an ultra-wide format. The training dataset contains 3 378 annotations and the validation dataset contains 852. Currently, no test set is present.\n",
    "\n",
    "<img src=\"assets/roadpoles_example.png\" alt=\"An example of an entry in the dataset\" width=\"1000\"/>\n",
    "\n",
    "###### © NAPLab \n",
    "\n",
    "Notably, as aforementioned and as visible in the example, the dataset is based on LiDAR images of poles. On one side, this reduces the feasibility of a potential result being used on e.g., a smartphone and increments the hardware cost for real-time inference. Modern smartphones such as the newer iPhone Pro and Pro Max models do have LiDAR sensors but with a limited reach of around 5 meters On the other side, LiDAR images, while being costly, are more available in the varying lighting conditions found in Norway. Nonetheless, the exploration in this project will be based on the LiDAR images in this dataset, evaluated on the potential performance on a hypothetical hardware-restrained edge device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 The Train/Val Split in this Paper\n",
    "\n",
    "Seeing that the dataset does not comprise a test dataset, the training dataset will be utilized to create a new train/validation split. The original validation dataset will be used for comparing the end result to other solutions, effectively acting as the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Bibtex Reference to the Dataset\n",
    "\n",
    "```biblatex\n",
    "    @misc{\n",
    "        polpolpol-pol-det_dataset,\n",
    "        title = { polpolpol pol det Dataset },\n",
    "        type = { Open Source Dataset },\n",
    "        author = { DURGA PRASAD },\n",
    "        howpublished = { \\url{ https://universe.roboflow.com/durga-prasad-hmjq7/polpolpol-pol-det } },\n",
    "        url = { https://universe.roboflow.com/durga-prasad-hmjq7/polpolpol-pol-det },\n",
    "        journal = { Roboflow Universe },\n",
    "        publisher = { Roboflow },\n",
    "        year = { 2024 },\n",
    "        month = { oct },\n",
    "        note = { visited on 2024-11-23 },\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the end goal is to produce an accurate model that can be performant for real-time inference on a hardware-restricted edge device, the goal is to use a lightweight model. In my previous exploratory study in the TDT17 Visual Intelligence course, I stipulated the following comparative overview of performance metrics of lightweight Object Detection (OD) models:\n",
    "\n",
    "<img src=\"assets/yolo-comparison.png\" alt=\"A comparison between YOLO models and EfficientDet\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Overview by Sindre Øyen, based on data from Ultralytics and EfficientDet (Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above highlights the performance of different real-time Object Detection (OD) models on the Microsoft Common Objects in Context (COCO) dataset, which often serves as a benchmark for evaluating OD models. EfficientDet-D1 has low computational requirements while maintaining reasonable accuracy, with a reasonable precision-to-computation for edge-device deployment. However, its accuracy (mAP) is only slightly better than the smallest YOLO model, YOLO11n. For tasks requiring higher precision, EfficientDet models have rapidly increasing computational needs for the larger models (e.g., EfficientDet-D2, D3), effectively making EfficientDet less ideal for edge-device deployment.\n",
    "\n",
    "On the other side, the YOLO11 series has a slower increase in computational demands for increased model size. Among the lightweight models, YOLO11s represents the best precision-to-computation trade-off - with superior precision to e.g., the EfficientDet-D3 model with 14% less floating point operations per second (FLOPs). Moreover, the YOLO11 series is specifically designed for real-time usage, with optimized inference speeds that are essential for edge deployment. YOLO11s, in particular, has both a compact model architecture and a solid detection performance and is thus a good starting point for this project, focusing on achieving reliable, real-time pole detection on edge-devices.\n",
    "\n",
    "In summary, the hypothesis is that YOLO11s will deliver the best precision-to-efficiency ratio for this use case, emphasizing effective detection of road poles while also considering compatibility with the computational limits of edge-devices. Further exploration may refine this initial choice of model, but YOLO11s proves a strong foundation based on benchmarked results and architectural requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# Path to dataset\n",
    "dataset_path = os.path.join(\"..\", \"data\", \"Poles\")\n",
    "data_yaml = os.path.join(dataset_path, \"data.yaml\")\n",
    "\n",
    "# Path to model with pre-trained weights\n",
    "pretrained_model = os.path.join(\"..\", \"models\", \"pre-trained\", \"yolo11s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "generic_type: type \"_InterpolationType\" is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/models/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastsam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrtdetr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/models/fastsam/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/models/fastsam/model.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/engine/model.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Results\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HUB_WEB_ROOT, HUBTrainingSession\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/cfg/__init__.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Union\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ASSETS,\n\u001b[1;32m     14\u001b[0m     ASSETS_URL,\n\u001b[1;32m     15\u001b[0m     DEFAULT_CFG,\n\u001b[1;32m     16\u001b[0m     DEFAULT_CFG_DICT,\n\u001b[1;32m     17\u001b[0m     DEFAULT_CFG_PATH,\n\u001b[1;32m     18\u001b[0m     DEFAULT_SOL_DICT,\n\u001b[1;32m     19\u001b[0m     IS_VSCODE,\n\u001b[1;32m     20\u001b[0m     LOGGER,\n\u001b[1;32m     21\u001b[0m     RANK,\n\u001b[1;32m     22\u001b[0m     ROOT,\n\u001b[1;32m     23\u001b[0m     RUNS_DIR,\n\u001b[1;32m     24\u001b[0m     SETTINGS,\n\u001b[1;32m     25\u001b[0m     SETTINGS_FILE,\n\u001b[1;32m     26\u001b[0m     TESTS_RUNNING,\n\u001b[1;32m     27\u001b[0m     IterableSimpleNamespace,\n\u001b[1;32m     28\u001b[0m     __version__,\n\u001b[1;32m     29\u001b[0m     checks,\n\u001b[1;32m     30\u001b[0m     colorstr,\n\u001b[1;32m     31\u001b[0m     deprecation_warn,\n\u001b[1;32m     32\u001b[0m     vscode_msg,\n\u001b[1;32m     33\u001b[0m     yaml_load,\n\u001b[1;32m     34\u001b[0m     yaml_print,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Define valid solutions\u001b[39;00m\n\u001b[1;32m     38\u001b[0m SOLUTION_MAP \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectCounter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate_heatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m }\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/utils/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/matplotlib/pyplot.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 Re-exported for typing.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     cm \u001b[38;5;28;01mas\u001b[39;00m cm, get_backend \u001b[38;5;28;01mas\u001b[39;00m get_backend, rcParams \u001b[38;5;28;01mas\u001b[39;00m rcParams, style \u001b[38;5;28;01mas\u001b[39;00m style)\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/matplotlib/image.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, cm\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# For clarity, names from _image are given explicitly in this module\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _image\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# For user convenience, the names from _image are also imported into\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# the image namespace\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_image\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401, F403\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: generic_type: type \"_InterpolationType\" is already registered!"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "generic_type: type \"_InterpolationType\" is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      3\u001b[0m pretrained \u001b[38;5;241m=\u001b[39m YOLO(pretrained_model)\n\u001b[1;32m      5\u001b[0m result \u001b[38;5;241m=\u001b[39m pretrained\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39mdata_yaml, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1024\u001b[39m,\u001b[38;5;241m128\u001b[39m])\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# default for reduced CPU utilization during training\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_yolo \u001b[38;5;28;01mas\u001b[39;00m checks\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/models/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfastsam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrtdetr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/models/fastsam/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAM\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/models/fastsam/model.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMPredictor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastSAMValidator\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/engine/model.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcfg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TASK2DATA, get_cfg, get_save_dir\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Results\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HUB_WEB_ROOT, HUBTrainingSession\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/cfg/__init__.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Union\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     ASSETS,\n\u001b[1;32m     14\u001b[0m     ASSETS_URL,\n\u001b[1;32m     15\u001b[0m     DEFAULT_CFG,\n\u001b[1;32m     16\u001b[0m     DEFAULT_CFG_DICT,\n\u001b[1;32m     17\u001b[0m     DEFAULT_CFG_PATH,\n\u001b[1;32m     18\u001b[0m     DEFAULT_SOL_DICT,\n\u001b[1;32m     19\u001b[0m     IS_VSCODE,\n\u001b[1;32m     20\u001b[0m     LOGGER,\n\u001b[1;32m     21\u001b[0m     RANK,\n\u001b[1;32m     22\u001b[0m     ROOT,\n\u001b[1;32m     23\u001b[0m     RUNS_DIR,\n\u001b[1;32m     24\u001b[0m     SETTINGS,\n\u001b[1;32m     25\u001b[0m     SETTINGS_FILE,\n\u001b[1;32m     26\u001b[0m     TESTS_RUNNING,\n\u001b[1;32m     27\u001b[0m     IterableSimpleNamespace,\n\u001b[1;32m     28\u001b[0m     __version__,\n\u001b[1;32m     29\u001b[0m     checks,\n\u001b[1;32m     30\u001b[0m     colorstr,\n\u001b[1;32m     31\u001b[0m     deprecation_warn,\n\u001b[1;32m     32\u001b[0m     vscode_msg,\n\u001b[1;32m     33\u001b[0m     yaml_load,\n\u001b[1;32m     34\u001b[0m     yaml_print,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Define valid solutions\u001b[39;00m\n\u001b[1;32m     38\u001b[0m SOLUTION_MAP \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjectCounter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate_heatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m }\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/ultralytics/utils/__init__.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/matplotlib/pyplot.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 Re-exported for typing.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     cm \u001b[38;5;28;01mas\u001b[39;00m cm, get_backend \u001b[38;5;28;01mas\u001b[39;00m get_backend, rcParams \u001b[38;5;28;01mas\u001b[39;00m rcParams, style \u001b[38;5;28;01mas\u001b[39;00m style)\n",
      "File \u001b[0;32m~/tdt17-miniProject/.env/lib64/python3.9/site-packages/matplotlib/image.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, cm\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# For clarity, names from _image are given explicitly in this module\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _image\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# For user convenience, the names from _image are also imported into\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# the image namespace\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_image\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401, F403\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: generic_type: type \"_InterpolationType\" is already registered!"
     ]
    }
   ],
   "source": [
    "pretrained = YOLO(pretrained_model)\n",
    "\n",
    "result = pretrained.train(data=data_yaml, epochs=100, imgsz=[1024,128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5 Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 Methods / Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 7 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 8.2 Key Learning Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## References\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
